{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I part 2 starter vi ud med at indlæse vores 'train_set.csv', 'validation_set.csv' og 'test_set.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_set.csv')\n",
    "val_data = pd.read_csv('validation_set.csv')\n",
    "test_data = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Indlæs træningsdata\n",
    "train_data = pd.read_csv('train_set.csv')\n",
    "\n",
    "# Erstat NaN-værdier i 'stemmed_content' med en tom streng\n",
    "train_data['stemmed_content'].fillna('', inplace=True)\n",
    "\n",
    "# Definer dine kategorier\n",
    "reliable_categories = ['reliable', 'political']\n",
    "fake_categories = ['fake', 'bias', 'conspiracy', 'hate', 'junksci', 'rumor', 'unreliable', 'satire']\n",
    "\n",
    "# Opret en funktion, der omdanner 'type' til binære værdier\n",
    "def map_to_binary(article_type):\n",
    "    if article_type in reliable_categories:\n",
    "        return 1  # 'reliable'\n",
    "    elif article_type in fake_categories:\n",
    "        return 0  # 'fake'\n",
    "    # Sikrer, at funktionen returnerer 0 for alle andre tilfælde, hvilket eliminerer risikoen for NaN-værdier\n",
    "    return 0  \n",
    "\n",
    "# Anvend denne funktion på dit datasæt for at oprette en binær label\n",
    "y_train = train_data['type'].apply(map_to_binary)\n",
    "\n",
    "# Nu er 'y_train' klar uden risiko for NaN-værdier\n",
    "X_train = train_data['stemmed_content']  # 'X_train' er også klar til brug\n",
    "\n",
    "# Opret en pipeline med TF-IDF og logistisk regression, øg antallet af iterationer\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))  # Øg antallet af iterationer\n",
    "])\n",
    "\n",
    "# Træn modellen på træningsdata\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Her er den del hvor vi indlæser valideringsdata og forudsiger\n",
    "# Antager at du har en 'val_set.csv' som valideringsdatasæt\n",
    "val_data = pd.read_csv('validation_set.csv')\n",
    "val_data['stemmed_content'].fillna('', inplace=True)\n",
    "X_val = val_data['stemmed_content']\n",
    "y_val = val_data['type'].apply(map_to_binary)\n",
    "\n",
    "# Brug pipelinen til at forudsige på valideringsdata\n",
    "y_pred = pipeline.predict(X_val)\n",
    "\n",
    "# Beregn og udskriv præcision for valideringsdata\n",
    "val_accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation accuracy: {val_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
